{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":28903,"sourceType":"datasetVersion","datasetId":22535},{"sourceId":4762389,"sourceType":"datasetVersion","datasetId":2756562}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.677582Z","iopub.execute_input":"2025-09-19T19:46:42.678047Z","iopub.status.idle":"2025-09-19T19:46:42.685028Z","shell.execute_reply.started":"2025-09-19T19:46:42.678001Z","shell.execute_reply":"2025-09-19T19:46:42.683886Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"classifier= Sequential() #initializing the CNN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.687641Z","iopub.execute_input":"2025-09-19T19:46:42.687976Z","iopub.status.idle":"2025-09-19T19:46:42.712521Z","shell.execute_reply.started":"2025-09-19T19:46:42.687954Z","shell.execute_reply":"2025-09-19T19:46:42.711253Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"# Ist step of Convoltional layer to get feature maps using feature detector\nclassifier.add(Convolution2D(filters=32, # output feature maps\n                             kernel_size=(3,3), # matrix size for feature detector\n                             input_shape=(64, 64, 3), # input image shape, 3 is for rgb coloured image with 128*128 px\n                             kernel_initializer='he_uniform', # weights distriution\n                             activation='relu')) # activation function","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.713522Z","iopub.execute_input":"2025-09-19T19:46:42.713882Z","iopub.status.idle":"2025-09-19T19:46:42.750647Z","shell.execute_reply.started":"2025-09-19T19:46:42.713852Z","shell.execute_reply":"2025-09-19T19:46:42.749732Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"# 2nd Pooling layer\nclassifier.add(MaxPooling2D(pool_size=(2,2)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.752661Z","iopub.execute_input":"2025-09-19T19:46:42.752959Z","iopub.status.idle":"2025-09-19T19:46:42.772544Z","shell.execute_reply.started":"2025-09-19T19:46:42.752930Z","shell.execute_reply":"2025-09-19T19:46:42.771271Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"#2nd convolutional and pooling layer.\nclassifier.add(Convolution2D(filters=32,\n                             kernel_size=(3,3), \n                             kernel_initializer='he_uniform', \n                             activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.773932Z","iopub.execute_input":"2025-09-19T19:46:42.774291Z","iopub.status.idle":"2025-09-19T19:46:42.812552Z","shell.execute_reply.started":"2025-09-19T19:46:42.774266Z","shell.execute_reply":"2025-09-19T19:46:42.811421Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"# Step 3 - Flattening\nclassifier.add(Flatten())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.813976Z","iopub.execute_input":"2025-09-19T19:46:42.814236Z","iopub.status.idle":"2025-09-19T19:46:42.824595Z","shell.execute_reply.started":"2025-09-19T19:46:42.814216Z","shell.execute_reply":"2025-09-19T19:46:42.823161Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"#Step 4 full connection in which input we have from flattening\n\nclassifier.add(Dense(units=128,kernel_initializer='glorot_uniform', activation='relu')) \n#step 5 output layer\nclassifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.825802Z","iopub.execute_input":"2025-09-19T19:46:42.826217Z","iopub.status.idle":"2025-09-19T19:46:42.883206Z","shell.execute_reply.started":"2025-09-19T19:46:42.826176Z","shell.execute_reply":"2025-09-19T19:46:42.882060Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.883962Z","iopub.execute_input":"2025-09-19T19:46:42.884262Z","iopub.status.idle":"2025-09-19T19:46:42.888947Z","shell.execute_reply.started":"2025-09-19T19:46:42.884241Z","shell.execute_reply":"2025-09-19T19:46:42.887818Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"#applying all the transformation we want to apply to training data set\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.889981Z","iopub.execute_input":"2025-09-19T19:46:42.890576Z","iopub.status.idle":"2025-09-19T19:46:42.914551Z","shell.execute_reply.started":"2025-09-19T19:46:42.890542Z","shell.execute_reply":"2025-09-19T19:46:42.913215Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"#Rescling the test data set images to use for validation.\ntest_datagen= ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.917149Z","iopub.execute_input":"2025-09-19T19:46:42.917603Z","iopub.status.idle":"2025-09-19T19:46:42.940621Z","shell.execute_reply.started":"2025-09-19T19:46:42.917570Z","shell.execute_reply":"2025-09-19T19:46:42.938958Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"#Getting My training data ready for validation, so it will read all the data with the px size we gave.\n\ntraining_set= train_datagen.flow_from_directory(directory= '/kaggle/input/dogs-cats-images/',\n                                               target_size=(64,64), # As we choose 64*64 for our convolution model\n                                               batch_size=50,\n                                               class_mode='binary' # for 2 class binary \n                                               )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:42.942288Z","iopub.execute_input":"2025-09-19T19:46:42.942798Z","iopub.status.idle":"2025-09-19T19:46:47.622549Z","shell.execute_reply.started":"2025-09-19T19:46:42.942761Z","shell.execute_reply":"2025-09-19T19:46:47.621161Z"}},"outputs":[{"name":"stdout","text":"Found 20000 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"#Getting My test data ready for validation, so it will read all the data with the px size we gave.\n\ntest_set= test_datagen.flow_from_directory(directory= '/kaggle/input/dogs-cats-images/',\n                                               target_size=(64,64), # As we choose 64*64 for our convolution model\n                                               batch_size=50,\n                                               class_mode='binary' # for 2 class binary\n                                          )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T19:46:47.623841Z","iopub.execute_input":"2025-09-19T19:46:47.624250Z","iopub.status.idle":"2025-09-19T19:46:47.918918Z","shell.execute_reply.started":"2025-09-19T19:46:47.624216Z","shell.execute_reply":"2025-09-19T19:46:47.917982Z"}},"outputs":[{"name":"stdout","text":"Found 20000 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"classifier.fit(training_set, #training data to fit\n                        steps_per_epoch=8000, # Data in training set\n                        epochs=5, # No of epochs to run\n                        validation_data=test_set, # Test or validation set\n                        validation_steps=2000 # no of data point for validation\n                        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T20:01:36.005207Z","iopub.execute_input":"2025-09-19T20:01:36.005560Z","iopub.status.idle":"2025-09-19T20:13:55.808826Z","shell.execute_reply.started":"2025-09-19T20:01:36.005536Z","shell.execute_reply":"2025-09-19T20:13:55.807832Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 18ms/step - accuracy: 0.4970 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\nEpoch 2/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 18ms/step - accuracy: 0.4911 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\nEpoch 3/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 19ms/step - accuracy: 0.4976 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\nEpoch 5/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 19ms/step - accuracy: 0.4932 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n","output_type":"stream"},{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79466ee87710>"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"# Part 3 - Making new predictions\n\nimport numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('/kaggle/input/single-prediction-cat-or-dog/Single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n# Loading the image and converting the pixels into array whcih will be used as input to predict.\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = classifier.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\n\n\nprint(\"Predicted output:\", prediction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T20:17:10.570350Z","iopub.execute_input":"2025-09-19T20:17:10.570752Z","iopub.status.idle":"2025-09-19T20:17:10.698613Z","shell.execute_reply.started":"2025-09-19T20:17:10.570726Z","shell.execute_reply":"2025-09-19T20:17:10.697605Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\nPredicted output: cat\n","output_type":"stream"}],"execution_count":87}]}